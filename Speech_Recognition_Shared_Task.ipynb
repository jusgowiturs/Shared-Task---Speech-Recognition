{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech_Recognition_Shared_Task.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPeSPYfsP/dLIueML+Ck+nO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jusgowiturs/Shared-Task---Speech-Recognition/blob/main/Speech_Recognition_Shared_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shared Task of Speech Recognition\n"
      ],
      "metadata": {
        "id": "SWiRVeC57EeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>This shared task consist of 36 tamil audio files and 36 tamil transcript files. The task is to recognize audio content and frame text as I think\n",
        "</p>\n",
        "\n",
        "<h3>Following library packages are imported</h3>\n",
        "<ul>\n",
        "  <li>drive from google colab - For mounting file</li>\n",
        "  <li>os - for dir access</li>\n",
        "  <li></li>\n",
        "</ul>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9fa4nW-D7MT-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ssER5cGtPXD",
        "outputId": "aea92e85-2866-408b-d072-23b438ecc5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Path set to \"/content/drive/My Drive/Academics\\ Projects/Shared_Task_Speech_Recognition\"\n",
        "###### Clone Audo and transcript file directly from my github page"
      ],
      "metadata": {
        "id": "XqPc8X-H8S9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition"
      ],
      "metadata": {
        "id": "GzLamj6JtaIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda66015-e86c-4a3b-9186-78e18571afc9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jusgowiturs/Shared-Task---Speech-Recognition.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQiw8yK1uLin",
        "outputId": "7e2c7c96-731f-4ecf-c99d-2f157e1fbf2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Shared-Task---Speech-Recognition'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Total 107 (delta 0), reused 0 (delta 0), pack-reused 107\u001b[K\n",
            "Receiving objects: 100% (107/107), 370.64 MiB | 13.88 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Checking out files: 100% (73/73), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Shared-Task---Speech-Recognition/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSNzTD60uXiL",
        "outputId": "eb1f70bf-1a2b-4b15-889d-66164d25430f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fwgb9HjEuoe0",
        "outputId": "5c99c1ee-9ff6-4ee7-ddef-117f908ca215"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition'"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GxSlBO_Lv6nH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Making Path of Audio and Path of Transcript joined together using map function"
      ],
      "metadata": {
        "id": "6PXd4ZJ68s6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Grouping_audiotext_path(dir1,dir2):\n",
        "  path =os.getcwd()\n",
        "  return (path+'/Audio/'+dir1,path+'/Transcript/'+dir2)"
      ],
      "metadata": {
        "id": "QhpqLyT923Ej"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_text_path = tuple(map(Grouping_audiotext_path,os.listdir('./Audio'),os.listdir('./Transcript')))\n",
        "audio_text_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF2GuV2cwFe6",
        "outputId": "ae3b7ce9-b561-4aa5-ffbf-97a95a0bb67c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 1.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 1.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 10.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 10.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 11.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 11.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 12.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 12.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 13.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 13.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 14.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 14.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 15.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 15.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 16.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 16.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 17.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 17.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 18.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 18.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 19.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 19.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 2.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 2.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 20.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 20.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 21.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 21.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 22.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 22.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 23.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 23.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 24.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 24.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 25.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 25.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 26.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 26.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 27.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 27.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 28.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 28.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 29.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 29.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 3.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 3.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 30.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 30.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 31.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 31.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 32.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 32.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 33.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 33.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 34.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 34.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 35.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 35.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 36.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 36.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 4.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 4.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 5.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 5.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 6.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 6.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 7.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 7.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 8.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 8.docx'),\n",
              " ('/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Audio/Audio - 9.wav',\n",
              "  '/content/drive/My Drive/Academics Projects/Shared_Task_Speech_Recognition/Shared-Task---Speech-Recognition/Transcript/Audio - 9.docx'))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from wave import open"
      ],
      "metadata": {
        "id": "twPPJ6nP5F78"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open(audio_text_path[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lXwi0I595AB",
        "outputId": "3bedfc55-115b-40ae-d0e3-fd681504f22d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wave.Wave_read at 0x7f4153bc1350>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wave."
      ],
      "metadata": {
        "id": "r6LjuYAQ_vki"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}